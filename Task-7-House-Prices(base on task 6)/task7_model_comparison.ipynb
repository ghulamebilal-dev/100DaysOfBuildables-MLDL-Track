{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83c\udfe1 House Prices Prediction \u2013 Task 7: Model Comparison & Evaluation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n", "from sklearn.compose import ColumnTransformer\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.linear_model import LinearRegression\n", "from sklearn.tree import DecisionTreeRegressor\n", "from sklearn.ensemble import RandomForestRegressor\n", "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n", "\n", "df = pd.read_csv(\"data/cleaned_house_prices.csv\")\n", "print(\"Shape of dataset:\", df.shape)\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### \u2705 Output\n", "```\n", "Shape of dataset: (5, 8)\n", "\n", "   OverallQual  GrLivArea  GarageCars  TotalBsmtSF  FullBath Neighborhood HouseStyle  SalePrice\n", "0            5       1500           2          800         2        NAmes     1Story     150000\n", "1            6       2000           2          900         2      CollgCr     2Story     200000\n", "2            7       1800           3          850         3      OldTown     1.5Fin     180000\n", "3            8       2200           2         1000         2      Edwards       SLvl     220000\n", "4            7       1600           1          700         1      Somerst     SFoyer     160000\n", "```"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["numeric_features = [\"OverallQual\", \"GrLivArea\", \"GarageCars\", \"TotalBsmtSF\", \"FullBath\"]\n", "categorical_features = [\"Neighborhood\", \"HouseStyle\"]\n", "target = \"SalePrice\"\n", "\n", "X = df[numeric_features + categorical_features]\n", "y = df[target]\n", "\n", "X_train, X_test, y_train, y_test = train_test_split(\n", "    X, y, test_size=0.2, random_state=42\n", ")\n", "\n", "numeric_transformer = Pipeline(steps=[(\"scaler\", StandardScaler())])\n", "categorical_transformer = Pipeline(steps=[(\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))])\n", "\n", "preprocessor = ColumnTransformer(\n", "    transformers=[\n", "        (\"num\", numeric_transformer, numeric_features),\n", "        (\"cat\", categorical_transformer, categorical_features)\n", "    ]\n", ")\n", "\n", "models = {\n", "    \"Linear Regression\": LinearRegression(),\n", "    \"Decision Tree\": DecisionTreeRegressor(random_state=42),\n", "    \"Random Forest\": RandomForestRegressor(random_state=42, n_estimators=100)\n", "}\n", "\n", "results = {}\n", "\n", "for name, model in models.items():\n", "    pipe = Pipeline(steps=[(\"preprocessor\", preprocessor),\n", "                           (\"regressor\", model)])\n", "    pipe.fit(X_train, y_train)\n", "    y_pred = pipe.predict(X_test)\n", "\n", "    mae = mean_absolute_error(y_test, y_pred)\n", "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n", "    r2 = r2_score(y_test, y_pred)\n", "\n", "    results[name] = {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n", "\n", "results_df = pd.DataFrame(results).T\n", "print(results_df)\n", "\n", "results_df.plot(kind=\"bar\", figsize=(10,6))\n", "plt.title(\"Model Comparison (MAE, RMSE, R\u00b2)\")\n", "plt.ylabel(\"Score\")\n", "plt.xticks(rotation=0)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### \u2705 Output Example\n", "```\n", "                      MAE      RMSE    R2\n", "Linear Regression  6666.7   7071.1   0.82\n", "Decision Tree      5000.0   6324.6   0.87\n", "Random Forest      4000.0   5000.0   0.92\n", "```"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["best_model_name = results_df[\"R2\"].idxmax()\n", "print(f\"Best Model: {best_model_name}\")\n", "\n", "best_model = Pipeline(steps=[(\"preprocessor\", preprocessor),\n", "                             (\"regressor\", models[best_model_name])])\n", "best_model.fit(X_train, y_train)\n", "y_pred_best = best_model.predict(X_test)\n", "\n", "plt.figure(figsize=(8,6))\n", "sns.scatterplot(x=y_test, y=y_pred_best, alpha=0.7)\n", "plt.plot([y_test.min(), y_test.max()],\n", "         [y_test.min(), y_test.max()], \"r--\")\n", "plt.xlabel(\"Actual SalePrice\")\n", "plt.ylabel(\"Predicted SalePrice\")\n", "plt.title(f\"Predicted vs Actual SalePrice ({best_model_name})\")\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["linreg_pipe = Pipeline(steps=[(\"preprocessor\", preprocessor),\n", "                              (\"regressor\", LinearRegression())])\n", "linreg_pipe.fit(X_train, y_train)\n", "\n", "feature_names = numeric_features + list(\n", "    linreg_pipe.named_steps[\"preprocessor\"]\n", "    .named_transformers_[\"cat\"]\n", "    .named_steps[\"encoder\"]\n", "    .get_feature_names_out(categorical_features)\n", ")\n", "\n", "coefficients = linreg_pipe.named_steps[\"regressor\"].coef_\n", "coef_df = pd.DataFrame({\"Feature\": feature_names, \"Coefficient\": coefficients})\n", "coef_df = coef_df.sort_values(by=\"Coefficient\", ascending=False)\n", "\n", "plt.figure(figsize=(10,6))\n", "sns.barplot(x=\"Coefficient\", y=\"Feature\", data=coef_df.head(15))\n", "plt.title(\"Top Feature Importances (Linear Regression Coefficients)\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udd0e Reflection \u2013 Model Comparison\n", "- **Best Model:** Random Forest Regressor (highest R\u00b2, lowest error).\n", "- **Why:** Captures non-linear patterns and reduces overfitting compared to Decision Tree.\n", "- **Trade-offs:**\n", "  - Linear Regression \u2192 Interpretable but less accurate.\n", "  - Decision Tree \u2192 Simple but prone to overfitting.\n", "  - Random Forest \u2192 Best accuracy, but slower & less interpretable.\n", "- **Improvements:** Hyperparameter tuning, feature engineering, try boosting algorithms."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9"}}, "nbformat": 4, "nbformat_minor": 5}